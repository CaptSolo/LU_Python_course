{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LU Logo](https://www.lu.lv/fileadmin/user_upload/LU.LV/www.lu.lv/Logo/Logo_jaunie/LU_logo_LV_horiz.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - vadošā Python datu analīzes bibliotēka\n",
    "\n",
    "Pandas ir jaudīga atvērtā pirmkoda Python datu analīzes un apstrādes bibliotēka. \n",
    "\n",
    "Tā nodrošina divas galvenās datu struktūras: **Series** (1-dimensiju) and **DataFrame** (2-dimensiju), kas ļauj organizēt, attīrīt un apstrādāt datu kopas. Ar bagātīgu funkciju kopumu dažādu datu formātu lasīšanai un rakstīšanai, kā arī ar visaptverošiem rīkiem datu pārveidošanai un izpētei, Pandas ir kļuvusi par neaizstājamu rīku datu zinātnes un analītikas kopienās.\n",
    "\n",
    "Pandas ir plaši izmantota atvērtā koda bibliotēka, kas tiek aktīvi attīstīta un ir ar lielisku dokumentāciju.\n",
    "\n",
    "Vietne: http://pandas.pydata.org/\n",
    "\n",
    "## Pandas radītājs — Vess Makkinijs (Wes McKinney)\n",
    "\n",
    "Pandas izveidoja Vess Makkinijs 2008. gadā. Viņš sāka izstrādāt Pandas, strādājot uzņēmumā AQR Capital Management, galvenokārt tāpēc, ka viņam bija nepieciešams elastīgs rīks kvantitatīvai finanšu datu analīzei. Vēlāk Vess Makkinijs izdeva grāmatu \"Python for Data Analysis\", kurā ir detalizēti apskatīta Pandas bibliotēka, kas palīdzēja tās popularizēšanā datu zinātnes kopienā.\n",
    "\n",
    "[Python for Data Analysis book 3rd ed](https://www.amazon.com/Python-Data-Analysis-Wrangling-Jupyter-dp-109810403X/dp/109810403X)\n",
    "\n",
    "\n",
    "![Python for Data Analysis book](https://m.media-amazon.com/images/I/51J1XFfaD4L._SX379_BO1,204,203,200_.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodarbības saturs\n",
    "\n",
    "Mēs apskatīsim sekojošas tēmas:\n",
    "\n",
    "* Pandas instalēšana\n",
    "* Pandas datu struktūras\n",
    "  * `Series`\n",
    "  * `DataFrames`\n",
    "  * `DateRange`\n",
    "* datu nolasīšana no datnēm\n",
    "* Pandas datu izvēle un indeksēšana\n",
    "* Pandas datu apstrāde\n",
    "* Pandas datu apkopošana un grupēšana\n",
    "* Pandas datu vizualizācija\n",
    "\n",
    "## Prasības priekšzināšanām\n",
    "\n",
    "* Python sintakse\n",
    "* Python datu tipi\n",
    "* Python operatori\n",
    "* Nosacījumu izteiksmes, zarošanās ar if, elif, else\n",
    "* Cikli: for un while\n",
    "* Funkcijas\n",
    "* imports, moduļi un pakotnes\n",
    "* Datu struktūras: saraksti, korteži, vārdnīcas, kopas\n",
    "* Failu ievade/izvade\n",
    "* Objektorientētās programmēšanas pamati - Klases un objekti\n",
    "* NumPy pamati\n",
    "\n",
    "## Nodarbības mērķi\n",
    "\n",
    "Nodarbības beigās Jums ir jāspēj:\n",
    "\n",
    "* instalēt Pandas\n",
    "* izveidot Pandas `Series` un `DataFrames`\n",
    "* nolasīt datus no datnēm\n",
    "* izvēlēties un indeksēt Pandas datu struktūrās esošus datus\n",
    "* apstrādāt Pandas datu struktūrās esošus datus\n",
    "* apkopot un grupēt Pandas datu struktūrās esošus datus\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. tēma - Pandas uzstādīšana un pamatoperācijas\n",
    "\n",
    "### 1.1. Pandas importēšana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pārbaudīt vai mums ir pieejama Pandas bibliotēka\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"pandas not found\")\n",
    "\n",
    "# Retos gadījumos var rasties Pandas un Numpy versiju nesaderība.\n",
    "# Šādos gadījumos varat mēģināt atjaunināt Numpy, izmantojot šādu komandu:\n",
    "# !pip install --upgrade numpy\n",
    "# Komandrindā tā būtu komanda: pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drukāt Pandas versiju\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will also need numpy and matplotlib\n",
    "# Pandas utilizes numpy and matplotlib under the hood\n",
    "# thus you might need to install them as well\n",
    "\n",
    "import numpy as np\n",
    "# print version\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "# print matplotlib version\n",
    "print(f\"matplotlib version: {plt.matplotlib.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the max_rows parameter\n",
    "# max_rows is the maximum number of rows that will be displayed\n",
    "#pd.reset_option('display.max_rows')\n",
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pandas instalēšana\n",
    "\n",
    "Vispirms mums ir jāinstalē Pandas, ja tas vēl nav izdarīts.\n",
    "\n",
    "**Instalēšana no Jupyter Notebook šūnas:**\n",
    "\n",
    "```python\n",
    "!pip install pandas\n",
    "```\n",
    "\n",
    "Tas instalēs Pandas pašreizējā vidē (ir vēlams lietot Python virtuālo vidi).\n",
    "\n",
    "**Instalēšana no komandrindas:**\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "Šī komanda instalēs Pandas pašreizējā vidē.\n",
    "\n",
    "---\n",
    "\n",
    "Pandas ir daudz neobligāto atkarību, kuras ir jāinstalē atsevišķi:\n",
    "[Pandas Optional Dependencies](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html#install-optional-dependencies) \n",
    "\n",
    "Piemēram, lai instalētu Pandas ar papildu atbalstu Excel datnēm, izmantojiet šādu komandu:\n",
    "\n",
    "```bash\n",
    "pip install \"pandas[excel]\"\n",
    "```\n",
    "\n",
    "Šī komanda instalēs piecas citas pakotnes, kas nepieciešamas, lai strādātu ar Excel failiem.\n",
    "\n",
    "### DataFrame izveidošana\n",
    "\n",
    "DataFrame ir visbūtiskākā Pandas datu struktūra. Tā ir divdimensiju, heterogēna tabulas veida datu struktūra ar maināmu izmēru un  marķētām (labeled) asīm (rindām un kolonnām). DataFrame ir līdzīga Excel spreadsheet vai SQL tabulai vai arī Series objektus saturošai vārdnīcai (dictionary of Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one common data source of data is a dictionary\n",
    "# here keys represend column names and values are lists of data\n",
    "\n",
    "my_data = {\n",
    "    'Pilsēta': ['Rīga', 'Daugavpils', 'Liepāja'],\n",
    "    'Iedz.skaits': [630000, 82000, 69000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(my_data) # df is very common abbreviation for DataFrame object variable name\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use an existing column as an index\n",
    "# in this case we will save a reference to the new DataFrame object\n",
    "df2 = df.set_index(['Pilsēta'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access the data by index\n",
    "df2.loc[\"Rīga\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu nolasīšana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas can read data not just from files but also from web URLs:\n",
    "\n",
    "# city_data = pd.read_csv(\"data/iedz_skaits_2018.csv\", index_col=0)\n",
    "csv_url = \"https://github.com/CaptSolo/LU_Python_2023/raw/main/notebooks/data/iedz_skaits_2018.csv\"\n",
    "\n",
    "city_data = pd.read_csv(csv_url, index_col=0)\n",
    "\n",
    "# display first five columns - head() method\n",
    "city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(city_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot the data immediately - by default it will plot all columns\n",
    "# there are many options to customize the plot but default is usually a good start\n",
    "\n",
    "city_data.plot()\n",
    "# by default Pandas uses matplotlib for plotting - there are options to use other libraries\n",
    "plt.xticks(rotation=90) # simple way to rotate x-axis labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tēma - Pandas Series\n",
    "\n",
    "**Series** ir viendimensiju objektu masīvs, kas satur vērtību (līdzīgu NumPy tipiem) virkni un ar to saistītu datu birku masīvu — indeksu.\n",
    "\n",
    "**DataFrame** struktūra ir veidota uz Series objektu pamata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to create a series from a DataFrame is to select a single column\n",
    "# if your DataFrame has only one column you can use squeeze() method\n",
    "city_series = city_data.squeeze()\n",
    "# doc of Sqeeze: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.squeeze.html\n",
    "type(city_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get single value by index\n",
    "print(city_series[\"Liepāja\"]) # the __str__ method is called\n",
    "city_series[\"Liepāja\"] # the __repr__ method is called, note the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can perform operations on the series\n",
    "city_series.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can generate basic statistics for the series\n",
    "city_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can filter the data by some condition\n",
    "city_series[city_series < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmap = city_series < 1000 # we generate a bitmap of the same size as the series\n",
    "# now we will show a sample of our bitmap\n",
    "bitmap.sample(20)   # kādēļ sample() nevis head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select by the bitmap then sort the data\n",
    "city_series[bitmap].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_series[bitmap].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series izveide no saraksta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Pandas Series\n",
    "\n",
    "s = pd.Series([1,4,3.5,3,np.nan,0,-5])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can perform operations on whole Series in one go:\n",
    "\n",
    "s + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN = Not a Number (used for missing numerical values)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 4 \n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Often Series have an index identifying each data point with a label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledSeries = pd.Series([24, 77, -35, 31], index=['d', 'e', 'a', 'g'])\n",
    "labeledSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Working with Series data (with some similarities to dictionaries)\n",
    "\n",
    "labeledSeries['g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledSeries.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if a label is in the Series\n",
    "'d' in labeledSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get values from Series\n",
    "labeledSeries.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series Values are NumPy arrays\n",
    "type(labeledSeries.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select multiple values by index\n",
    "labeledSeries[['a','d']] # NOTE double list brackets!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generalize, Series behaves like a fixed-length, ordered dictionary with extra helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series var tikt izveidotas no vārdnīcas, nododot to pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citydict = {'Rīga': 630000, 'Daugavpils': 82000, 'Liepāja': 69000, 'Carnikava': 4800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries = pd.Series(citydict)\n",
    "cseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overwriting default index\n",
    "clist = ['Jūrmala', 'Rīga', 'Daugavpils', 'Ogre', 'Liepāja']\n",
    "\n",
    "cseries2 = pd.Series(citydict, index = clist)\n",
    "cseries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice Carnikava was lost, since the new index does not have it\n",
    "# and order was preserved from the given index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing data\n",
    "cseries2.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries3 = cseries + cseries2\n",
    "cseries3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so NaN + number = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can name the table and its index column\n",
    "\n",
    "cseries.name = \"Latvian Cities\"\n",
    "cseries.index.name = \"City\"\n",
    "cseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Index names\n",
    "cseries.index = ['RīgaIsOld', 'Daugavpils', 'LiepājaWind', 'CarnikavaIsNotaCity']\n",
    "cseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series values are mutable\n",
    "cseries['RīgaIsOld'] = 625000\n",
    "cseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use rename() method to rename individual elements\n",
    "cseries4 = cseries.rename(index={'RīgaIsOld':'RīgaRocks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseries4[\"RīgaRocks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uz skaitļiem (pozīciju) un uz birkām balstīti indeksi\n",
    "\n",
    "Darbs ar Pandas objektiem, kas ir indeksēti ar veseliem skaitļiem, bieži mulsina jaunus lietotājus, jo ir dažas atšķirības indeksēšanas semantikā salīdzinājumā ar Python iebūvētajām datu struktūrām, piemēram, sarakstiem un kortežiem. Piemēram, jūs varētu negaidīt, ka šāda komanda izraisīs kļūdu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(3.))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ser[-1]\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Šajā gadījumā Pandas varētu \"pāriet\" uz veselu skaitļu indeksēšanu, taču to ir grūti vispārīgi īstenot, neradot kļūdas.\n",
    "\n",
    "Piemēram, ja mums ir indekss ar vērtībām 0, 1, 2, tad ir grūti viennozīmīgi noteikt, ko lietotājs vēlas izmantot — uz birkām balstītu vai uz pozīciju balstītu indeksēšanu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With a non-integer index there is no potential for ambiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = pd.Series(np.arange(3.), index=['a', 'b', 'c'])\n",
    "ser2[-1] # note FutureWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regular slicing with an explicit index uses the index:\n",
    "ser2[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To keep things consistent, if you have an axis index containing integers, data selection\n",
    "## will always be label-oriented. \n",
    "\n",
    "# For more precise handling, use loc (for labels) or iloc (for integer index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: label indexing includes the endpoint, integer indexing does not\n",
    "ser.loc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ser.iloc[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loc iegūst rindas (vai kolonnas) ar konkrētām birkām no indeksa.\n",
    "\n",
    "* iloc iegūst rindas (vai kolonnas) konkrētās indeksa pozīcijās (tāpēc tas pieņem tikai veselus skaitļus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. tēma - Date Range izveide\n",
    "\n",
    "Datumu diapazoni tiek izmantoti kā indeksi laika sēriju datiem:\n",
    "* https://pandas.pydata.org/docs/user_guide/10min.html#time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get today's data in the form of YYYYMMDD string\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime(\"%Y%m%d\")\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(today, periods=15)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(today, periods=15, freq=\"W\") # note default W-SUN means weeks starting on Sunday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with Monday\n",
    "pd.date_range(today, periods=7, freq=\"W-MON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more on data_range frequency here\n",
    "# https://stackoverflow.com/questions/35339139/where-is-the-documentation-on-pandas-freq-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime is in the standard library (so all Python installations will have it)\n",
    "from datetime import date\n",
    "date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a data range starting from today\n",
    "months = pd.date_range(date.today().strftime(\"%Y-%m-%d\"), periods = 10, freq='BMS')\n",
    "# BMS means Business Month Start in US calendar\n",
    "months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. tēma - DataFrame\n",
    "\n",
    "DataFrame ir visbiežāk izmantotā Pandas datu struktūra. Tā ir 2-dimensiju datu tabula, kas satur sakārtotu kolonnu kolekciju.\n",
    "- katrai kolonnai var būt atšķirīgs datu tips (skaitlisks, teksts, boolean utt.).\n",
    "\n",
    "DataFrame ir gan rindu, gan kolonnu indeksi.\n",
    "\n",
    "To var uztvert kā sakārtotu Series vārdnīcu, kur visām Series ir kopīgs rindas indekss.\n",
    "\n",
    "DataFrame esošie dati tiek glabāti kā viens vai vairāki divdimensiju bloki (līdzīgi kā ndarray)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are different ways for creating DataFrames\n",
    "\n",
    "# A common way is to create it from a dict of equal-length lists or NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again column names are keys and values are lists of data\n",
    "data = {'city': ['Riga', 'Riga', 'Riga', 'Jurmala', 'Jurmala', 'Jurmala'],\n",
    "        'year': [1990, 2000, 2018, 2001, 2002, 2003],\n",
    "        'popul': [0.9, 0.75, 0.62, 0.09, 0.08, 0.06]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify the order of columns\n",
    "df2 = pd.DataFrame(data, columns=['year','city', 'popul','budget'])\n",
    "# note we did not previously have budget column, thus it will be filled with NaN\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing column simply given Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can set values for the new column all at once\n",
    "df2['budget']=300000000\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could pass specific values for the new column as well\n",
    "df2['budget']=[300000, 250000, 400000, 200000, 250000, 200000] # need to pass all values\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many ways of changing individual values\n",
    "\n",
    "## Recommended way of changing in place (same dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iat will let you assign values in specific cells by numerical index\n",
    "df2.iat[3,2] = 0.063 # so 3 is the row index, 2 is the column index\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting single column will give you series\n",
    "df2[\"budget\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2[\"budget\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want a single column dataframe then we use double brackets\n",
    "df2[[\"budget\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(df2[[\"budget\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete column by its name\n",
    "del df2[\"budget\"]\n",
    "# alterantive would be to use drop method\n",
    "# see docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateRange lietošana DataFrame izveidei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we still have our DateRange, we will use as an index\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(15,5), index=dates, columns=list('ABCDE'))\n",
    "# We passed 15 rows of 5 random elements and set index to dates and columns to our basic list elements\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also create a DataFrame from a dict where values are various types\n",
    "df2 = pd.DataFrame({ 'A' : 1.,\n",
    "                      'B' : pd.Timestamp('20130102'),\n",
    "                      'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                      'D' : np.array([3] * 4,dtype='int32'),\n",
    "                      'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                      'F' : 'foo' })\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most columns need matching length!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data type:\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## s = pd.Series([1,4,3.5,3,np.nan,0,-5])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again we either supply one value or exact number of values\n",
    "df3 = pd.DataFrame({ 'A' : 1.,\n",
    "                   'B' : pd.Timestamp('20180523'),\n",
    "                   'C' : s,\n",
    "                   'D' : [x**2 for x in range(7)],\n",
    "                   'E' : pd.Categorical(['test','train']*3+[\"train\"]),\n",
    "                   'F' : 'aha'\n",
    "                   })\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different datatypes for columns! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe statistika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe method gives basic statistics for numerical columns by default\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info method gives more detailed information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get statistics for non-numerical columns as well\n",
    "df3.describe(include='all') \n",
    "# note how NaNs are shown where statistics are not applicable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can show statistics for non-numericals only\n",
    "df3.describe(include=['object', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=1,ascending=False)\n",
    "# this sorts columns in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort by Axis in reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=0,ascending=False)\n",
    "# here we have sort by index in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more commonly we want to sort by values in some column\n",
    "df3.sort_values(by='C', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that NaN becomes last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can sort by multiple columns and supply sorting directions for each\n",
    "df3.sort_values(by=['E','C'], ascending=[True,False])\n",
    "# so here we lexicographically sort by E and when we have ties we sort by C numerically in reverse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu izvēle (selection) \n",
    "\n",
    "Piezīme: lai gan standarta Python / Numpy izteiksmes datu atlasei un iestatīšanai ir intuitīvas un ērtas interaktīvam darbam, ražošanas kodā ieteicams izmantot optimizētās Pandas datu piekļuves metodes — **.at**, **.iat**, **.loc** un **.iloc**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[:5] # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[2:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu izvēle pēc birkas\n",
    "\n",
    "Lai atlasītu datus lietojot birkas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0]] # so we used specific date as index to ge the row data as Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[2:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlase uz vairākām asīm pēc birkas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['A','B','C']]\n",
    "# we get all rows and only columns A, B and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[2:5], ['A','B','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20241113':'20241115',['B','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction in the dimensions of the returned object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20241114', [\"B\", \"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting scalars (single values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20241114', [\"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['20241114', [\"D\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[5],'D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu atlase pēc pozīcijas\n",
    "\n",
    "Mēs varam atlasīt datus pēc to pozīcijas ar **iloc** metodi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3] # so we got 4th row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By integer slices, acting similar to numpy/python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:5,:2]\n",
    "# so 3rd to 6th row (exclusive) and 1st to 3rd column (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By lists of integer position locations, similar to the numpy/python style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can supply lists of indices\n",
    "df.iloc[[3,5,1],[1,4,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2,2] # so 3rd row and 3rd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iat is very similar but you only can use single indices not slices or lists\n",
    "df.iat[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting fast access to a scalar (equivalent to the prior method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loģiskā indeksēšana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a single column’s values to select data\n",
    "df[df.A > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use filter on all columns to obtain bitmask\n",
    "df > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table cells that match given criteria\n",
    "df[df > 0.2]\n",
    "# so non matching cells are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we replace our filter values with NaN\n",
    "df[df < 0.2] = np.nan # so all values less than 0.2 are replaced with NaN\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values with some value\n",
    "df.fillna(value=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is also df.dropna() to drop any ROWS(!) with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame datu modificēšana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used fillna method yet we still have NaNs\n",
    "# why is that so?\n",
    "\n",
    "# because fillna returns a new DataFrame, it does not change the original one\n",
    "\n",
    "# many methods in Pandas work this way, they return a new object by default\n",
    "# they also have a parameter inplace that can be set to True to change the original object\n",
    "\n",
    "df.fillna(value=0.1, inplace=True) # will MODIFY the original DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([x**3 for x in range(15)], index=pd.date_range(today, periods=15))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add this new column to our DataFrame\n",
    "# since indexes are the same - specific DateRange here, Pandas will match them\n",
    "df['F'] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting cell values\n",
    "\n",
    "df.at[dates[1], 'A'] = 33\n",
    "# similarly we could use loc\n",
    "df.loc[dates[2], ['B']] = 66\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas metožu virknēšana\n",
    "\n",
    "Metožu virknēšana (method chaining) ļauj vienā Python komandā sakombinēt vairākas Pandas darbības.\n",
    "\n",
    "Piemēram:\n",
    "```\n",
    "df = df.drop(columns=[\"Rank\"])\n",
    "df = df.query(\"Province == 'Connacht'\")\n",
    "df.sort_values(\"Density (/ km2)\", ascending=False)\n",
    "```\n",
    "\n",
    "vietā var rakstīt:\n",
    "```\n",
    "df.drop(columns=[\"Rank\"]) \\\n",
    "  .query(\"Province == 'Connacht'\") \\\n",
    "  .sort_values(\"Density (/ km2)\", ascending=False)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: https://blanchardjulien.com/posts/chaining/\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def getDataframe(url_table,ind):\n",
    "    df = pd.read_html(url_table)[ind]\n",
    "    return df\n",
    "\n",
    "df_ie = getDataframe(\"https://en.wikipedia.org/wiki/Historical_population_of_Ireland\",1)\n",
    "df_ie.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ie.drop(columns=[\"Rank\", \"Change since previous census\"]) \\\n",
    "  .query(\"Province == 'Connacht'\") \\\n",
    "  .sort_values(\"Density (/ km2)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  df_ie.drop(columns=[\"Rank\", \"Change since previous census\"])\n",
    "    .query(\"Province == 'Connacht'\")\n",
    "    .sort_values(\"Density (/ km2)\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_data = pd.read_csv(\"data/iedz_skaits_2018.csv\", index_col=0)\n",
    "csv_url = \"https://github.com/CaptSolo/LU_Python_2023/raw/main/notebooks/data/iedz_skaits_2018.csv\"\n",
    "\n",
    "city_data = pd.read_csv(csv_url, index_col=0)\n",
    "\n",
    "# display first five columns - head() method\n",
    "city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    city_data.dropna()\n",
    "        .rename(columns={\"2018 Iedzīvotāju skaits gada sākumā\": \"Iedz. skaits\"})\n",
    "        .sort_values(by=\"Iedz. skaits\", ascending=False)\n",
    "        .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Darbības ar Series un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame metodes un īpašības:\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n",
    "        \n",
    "Series metodes un īpašības:\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "    \n",
    "Data Science Handbook:\n",
    "* [Data manipulation with Pandas](https://jakevdp.github.io/PythonDataScienceHandbook/index.html#3.-Data-Manipulation-with-Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[m for m in dir(df) if not m.startswith(\"_\")]\n",
    "# note mixture of methods and attributes, here A,B,C,D,E,F are attributes of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(15,5), index=dates, columns=list('ABCDE'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teksta operācijas (df.str.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "str1 = pd.Series(['APPle', 'baNAna', np.nan, 42, 'mangO'])\n",
    "# NOTE: if we supply mixed types, Pandas will convert all to strings - object type\n",
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[name for name in dir(str1.str) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(str1.str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda functions are anonymous functions\n",
    "# (functions defined without a name)\n",
    "\n",
    "# We can apply a function over all DataFrame elements:\n",
    "\n",
    "# in general it will be faster than iterating over rows or columns\n",
    "\n",
    "df.apply(lambda x: x*3) \n",
    "# this example is simple and could be done with df*3\n",
    "# we would use apply for more complex operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu grupēšana un apkopošana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'], \n",
    "                   'data': range(6)}, \n",
    "                  columns=['key', 'data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key') # we get a groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply aggregate functions to the groups obtaining a new DataFrame\n",
    "df.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df.groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datu apvienošana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge\n",
    "# often we will want to combine data from different sources\n",
    "\n",
    "left = pd.DataFrame({\"key\": [\"foo\", \"bar\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"bar\", \"other\"], \"rval\": [4, 5, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"key\")\n",
    "# thus we are merging on the key column\n",
    "# by default merge is inner join\n",
    "# meaning that only keys present in both DataFrames will be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might want to use different types of joins\n",
    "# for example left join will include all keys from the left DataFrame\n",
    "# here right join will include all keys from the right DataFrame\n",
    "pd.merge(left, right, on=\"key\", how=\"right\")\n",
    "# note how NaNs are used to fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darbības ar datnēm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to a CSV file\n",
    "df.to_csv(\"test_pandas2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from CSV file\n",
    "new_df = pd.read_csv(\"test_pandas2.csv\", index_col=0)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will raise an error if 'openpyxl' package is not installed\n",
    "df.to_excel('test_pandas.xlsx', sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_excel('test_pandas.xlsx', 'Sheet1', index_col=0, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darbības ar tīmekļa saturu\n",
    "\n",
    "Pandas prot nolasīt HTML tabulu saturu (ja vien HTML lapa izmanto tabulas).\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tables from an HTML page\n",
    "\n",
    "url = \"https://www.ss.com/lv/transport/cars/audi/\"\n",
    "\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tables matching a search string\n",
    "# use the 1st line as a header\n",
    "\n",
    "tables = pd.read_html(url, match=\"Sludinājumi\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laika sērijas (Time series)\n",
    "\n",
    "Laika sērijas ir īpaša datu veida forma, kurā laiks ir neatņemama sastāvdaļa. Laika sērijas dati ir bieži sastopami daudzās jomās, piemēram, ekonomikā, finansēs, bioloģijā, fizikā, medicīnā utt.\n",
    "\n",
    "**Pamatdoma** - laiks ir neatņemama sastāvdaļa, un laika sērijas dati ir sakārtoti augošā laika secībā.\n",
    "\n",
    "Laiks tātad šeit tiek sadalīts diskrētās laika vienībās(dienās, stundās, minūtes vai citās vienībās), un laika sērijas dati ir parasti sakārtoti vienādos laika intervālos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# first let's set seed for reproducibility\n",
    "np.random.seed(2024)\n",
    "# let's generate 10 years worth of random data using NumPy random.randn\n",
    "# docs: https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html\n",
    "periods=3650\n",
    "ts = pd.Series(np.random.randn(periods), index=pd.date_range(today, periods=periods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_series = ts.cumsum() # cumulative sum\n",
    "# tail() will show the last 5 elements\n",
    "cumulative_series.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_series[\"2027-01-01\":\"2029-01-01\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use rolling method to calculate rolling statistics\n",
    "# we supply a window size of 90 days here\n",
    "rolling_avg = cumulative_series.rolling(window=90).mean()\n",
    "rolling_avg # note how there is no average for the first 90 days - NaN because of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_avg.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Papildus resursi\n",
    "\n",
    "- Dokumentācija: http://pandas.pydata.org/pandas-docs/stable/\n",
    "- Pandas Cheat Sheet: https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf\n",
    "\n",
    "- https://www.dataschool.io/easier-data-analysis-with-pandas/ (video)\n",
    "\n",
    "- Apmācības materiāli: https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html\n",
    "  - [\"Getting started\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html) - see also the \"10 minutes to pandas\" section\n",
    "  - [\"Modern Pandas\"](http://tomaugspurger.github.io/modern-1-intro.html) tutorial\n",
    "  - [Python Data Science Handbook - Pandas](https://jakevdp.github.io/PythonDataScienceHandbook/index.html#3.-Data-Manipulation-with-Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
