{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LU Logo](https://www.lu.lv/fileadmin/user_upload/LU.LV/www.lu.lv/Logo/Logo_jaunie/LU_logo_LV_horiz.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. nedēļa: Darbības ar datnēm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopsavilkums\n",
    "\n",
    "Mēs apskatīsim šādus tematus:\n",
    "\n",
    "* Darbības ar direktorijām: to izveidošana, pārsaukšana, apskatīšana un dzēšana.\n",
    "  * Darbības ar `pathlib`, `glob` un `rglob`\n",
    "* Darbības ar teksta failiem (datnēm): to lasīšana, papildināšana un rakstīšana.\n",
    "  * Simbolu kodējuma problēmas\n",
    "* Binārās datnes\n",
    "* JSON datnes\n",
    "\n",
    "## Nodarbības mērķi\n",
    "\n",
    "Nodarbības beigās studenti pratīs:\n",
    "\n",
    "* Darboties ar direktorijām (folders)\n",
    "* Darboties ar datnēm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.7 (main, Oct 16 2024, 07:12:08) [Clang 18.1.8 ]\n"
     ]
    }
   ],
   "source": [
    "# import komandas parasti tiek liktas programmas sākumā\n",
    "\n",
    "# Python versijas pārbaude\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.tēma - Darbības ar direktorijām\n",
    "\n",
    "* [pathlib](https://docs.python.org/3/library/pathlib.html) – Objekt-orientēti failsistēmas ceļi (paths)\n",
    "* [os](https://docs.python.org/3/library/os.html) – Dažādas darbības ar datora operētājsistēmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ieimportēsim pathlib bibliotēkas Path klasi\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_module.py\n",
      "week_13_visualization_libraries.ipynb\n",
      "lena.png\n",
      "week_14_intermediate_Python_LV.ipynb\n",
      ".DS_Store\n",
      "in-class\n",
      "week_11_data_analysis_pandas_LV.ipynb\n",
      "week_2_key_programming_concepts.ipynb\n",
      "cities_titles.json\n",
      "Untitled.ipynb\n",
      "week_10_numerical_computation_numpy_LV.ipynb\n",
      "week_1_Python_basics_LV.ipynb\n",
      "week_15_web_Flask_Scrapy.ipynb\n",
      "my_module2.py\n",
      "week_14_intermediate_Python.ipynb\n",
      "week_15_web_Flask_Scrapy_LV.ipynb\n",
      "my_module3.py\n",
      "week_13_visualization_libraries_Plotly_LV.ipynb\n",
      "__pycache__\n",
      "week_7_practical_assignments_LV.ipynb\n",
      "week_10_numerical_computation_numpy.ipynb\n",
      "random_4x5_rounded.npy\n",
      "static\n",
      "week_4_functions_tuples_dictionaries_sets_LV.ipynb\n",
      "week_5_standard_library_modules_LV.ipynb\n",
      "week_4_practical_assignments_LV.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_8_classes_objects.ipynb\n",
      "week_13_visualization_libraries_LV.ipynb\n",
      "week_13_visualization_libraries_Plotly.ipynb\n",
      "templates\n",
      "week_7_file_handling_LV.ipynb\n",
      "iframe_figures\n",
      "week_8_classes_objects_LV.ipynb\n",
      ".ipynb_checkpoints\n",
      "random_4x5_rounded.csv\n",
      "week_1_Python_basics.ipynb\n",
      "week_11_data_analysis_pandas.ipynb\n",
      "week_7_file_handling.ipynb\n",
      "week_13_visualization_libraries_Matplotlib_LV.ipynb\n",
      "decorator_module.py\n",
      "week_2_key_programming_concepts_LV.ipynb\n",
      "week_7_dictionary.csv\n",
      "week_13_visualization_libraries_Matplotlib.ipynb\n",
      "week_5_standard_library_modules.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Patreizējās darba direktorijas satura apskatīšana\n",
    "\n",
    "# Ceļš uz patreizējo darba direktoriju\n",
    "cur_dir = Path(\".\")\n",
    "\n",
    "# Direktorijas satura apskatīšana (patvaļīgā secībā)\n",
    "for item in cur_dir.iterdir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      ".ipynb_checkpoints\n",
      "Untitled.ipynb\n",
      "__pycache__\n",
      "cities_titles.json\n",
      "decorator_module.py\n",
      "iframe_figures\n",
      "in-class\n",
      "lena.png\n",
      "my_module.py\n",
      "my_module2.py\n",
      "my_module3.py\n",
      "random_4x5_rounded.csv\n",
      "random_4x5_rounded.npy\n",
      "static\n",
      "templates\n",
      "week_10_numerical_computation_numpy.ipynb\n",
      "week_10_numerical_computation_numpy_LV.ipynb\n",
      "week_11_data_analysis_pandas.ipynb\n",
      "week_11_data_analysis_pandas_LV.ipynb\n",
      "week_13_visualization_libraries.ipynb\n",
      "week_13_visualization_libraries_LV.ipynb\n",
      "week_13_visualization_libraries_Matplotlib.ipynb\n",
      "week_13_visualization_libraries_Matplotlib_LV.ipynb\n",
      "week_13_visualization_libraries_Plotly.ipynb\n",
      "week_13_visualization_libraries_Plotly_LV.ipynb\n",
      "week_14_intermediate_Python.ipynb\n",
      "week_14_intermediate_Python_LV.ipynb\n",
      "week_15_web_Flask_Scrapy.ipynb\n",
      "week_15_web_Flask_Scrapy_LV.ipynb\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_Python_basics_LV.ipynb\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_2_key_programming_concepts_LV.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets_LV.ipynb\n",
      "week_4_practical_assignments_LV.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_5_standard_library_modules_LV.ipynb\n",
      "week_7_dictionary.csv\n",
      "week_7_file_handling.ipynb\n",
      "week_7_file_handling_LV.ipynb\n",
      "week_7_practical_assignments_LV.ipynb\n",
      "week_8_classes_objects.ipynb\n",
      "week_8_classes_objects_LV.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Sakārtosim direktorijas saturu alfabēta secībā\n",
    "\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PosixPath in module pathlib object:\n",
      "\n",
      "class PosixPath(Path, PurePosixPath)\n",
      " |  PosixPath(*args, **kwargs)\n",
      " |\n",
      " |  Path subclass for non-Windows systems.\n",
      " |\n",
      " |  On a POSIX system, instantiating a Path should return this object.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      PosixPath\n",
      " |      Path\n",
      " |      PurePosixPath\n",
      " |      PurePath\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods inherited from Path:\n",
      " |\n",
      " |  __enter__(self)\n",
      " |\n",
      " |  __exit__(self, t, v, tb)\n",
      " |\n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  absolute(self)\n",
      " |      Return an absolute version of this path by prepending the current\n",
      " |      working directory. No normalization or symlink resolution is performed.\n",
      " |\n",
      " |      Use resolve() to get the canonical path to a file.\n",
      " |\n",
      " |  chmod(self, mode, *, follow_symlinks=True)\n",
      " |      Change the permissions of the path, like os.chmod().\n",
      " |\n",
      " |  exists(self, *, follow_symlinks=True)\n",
      " |      Whether this path exists.\n",
      " |\n",
      " |      This method normally follows symlinks; to check whether a symlink exists,\n",
      " |      add the argument follow_symlinks=False.\n",
      " |\n",
      " |  expanduser(self)\n",
      " |      Return a new path with expanded ~ and ~user constructs\n",
      " |      (as returned by os.path.expanduser)\n",
      " |\n",
      " |  glob(self, pattern, *, case_sensitive=None)\n",
      " |      Iterate over this subtree and yield all existing files (of any\n",
      " |      kind, including directories) matching the given relative pattern.\n",
      " |\n",
      " |  group(self)\n",
      " |      Return the group name of the file gid.\n",
      " |\n",
      " |  hardlink_to(self, target)\n",
      " |      Make this path a hard link pointing to the same file as *target*.\n",
      " |\n",
      " |      Note the order of arguments (self, target) is the reverse of os.link's.\n",
      " |\n",
      " |  is_block_device(self)\n",
      " |      Whether this path is a block device.\n",
      " |\n",
      " |  is_char_device(self)\n",
      " |      Whether this path is a character device.\n",
      " |\n",
      " |  is_dir(self)\n",
      " |      Whether this path is a directory.\n",
      " |\n",
      " |  is_fifo(self)\n",
      " |      Whether this path is a FIFO.\n",
      " |\n",
      " |  is_file(self)\n",
      " |      Whether this path is a regular file (also True for symlinks pointing\n",
      " |      to regular files).\n",
      " |\n",
      " |  is_junction(self)\n",
      " |      Whether this path is a junction.\n",
      " |\n",
      " |  is_mount(self)\n",
      " |      Check if this path is a mount point\n",
      " |\n",
      " |  is_socket(self)\n",
      " |      Whether this path is a socket.\n",
      " |\n",
      " |  is_symlink(self)\n",
      " |      Whether this path is a symbolic link.\n",
      " |\n",
      " |  iterdir(self)\n",
      " |      Yield path objects of the directory contents.\n",
      " |\n",
      " |      The children are yielded in arbitrary order, and the\n",
      " |      special entries '.' and '..' are not included.\n",
      " |\n",
      " |  lchmod(self, mode)\n",
      " |      Like chmod(), except if the path points to a symlink, the symlink's\n",
      " |      permissions are changed, rather than its target's.\n",
      " |\n",
      " |  lstat(self)\n",
      " |      Like stat(), except if the path points to a symlink, the symlink's\n",
      " |      status information is returned, rather than its target's.\n",
      " |\n",
      " |  mkdir(self, mode=511, parents=False, exist_ok=False)\n",
      " |      Create a new directory at this given path.\n",
      " |\n",
      " |  open(self, mode='r', buffering=-1, encoding=None, errors=None, newline=None)\n",
      " |      Open the file pointed to by this path and return a file object, as\n",
      " |      the built-in open() function does.\n",
      " |\n",
      " |  owner(self)\n",
      " |      Return the login name of the file owner.\n",
      " |\n",
      " |  read_bytes(self)\n",
      " |      Open the file in bytes mode, read it, and close the file.\n",
      " |\n",
      " |  read_text(self, encoding=None, errors=None)\n",
      " |      Open the file in text mode, read it, and close the file.\n",
      " |\n",
      " |  readlink(self)\n",
      " |      Return the path to which the symbolic link points.\n",
      " |\n",
      " |  rename(self, target)\n",
      " |      Rename this path to the target path.\n",
      " |\n",
      " |      The target path may be absolute or relative. Relative paths are\n",
      " |      interpreted relative to the current working directory, *not* the\n",
      " |      directory of the Path object.\n",
      " |\n",
      " |      Returns the new Path instance pointing to the target path.\n",
      " |\n",
      " |  replace(self, target)\n",
      " |      Rename this path to the target path, overwriting if that path exists.\n",
      " |\n",
      " |      The target path may be absolute or relative. Relative paths are\n",
      " |      interpreted relative to the current working directory, *not* the\n",
      " |      directory of the Path object.\n",
      " |\n",
      " |      Returns the new Path instance pointing to the target path.\n",
      " |\n",
      " |  resolve(self, strict=False)\n",
      " |      Make the path absolute, resolving all symlinks on the way and also\n",
      " |      normalizing it.\n",
      " |\n",
      " |  rglob(self, pattern, *, case_sensitive=None)\n",
      " |      Recursively yield all existing files (of any kind, including\n",
      " |      directories) matching the given relative pattern, anywhere in\n",
      " |      this subtree.\n",
      " |\n",
      " |  rmdir(self)\n",
      " |      Remove this directory.  The directory must be empty.\n",
      " |\n",
      " |  samefile(self, other_path)\n",
      " |      Return whether other_path is the same or not as this file\n",
      " |      (as returned by os.path.samefile()).\n",
      " |\n",
      " |  stat(self, *, follow_symlinks=True)\n",
      " |      Return the result of the stat() system call on this path, like\n",
      " |      os.stat() does.\n",
      " |\n",
      " |  symlink_to(self, target, target_is_directory=False)\n",
      " |      Make this path a symlink pointing to the target path.\n",
      " |      Note the order of arguments (link, target) is the reverse of os.symlink.\n",
      " |\n",
      " |  touch(self, mode=438, exist_ok=True)\n",
      " |      Create this file with the given access mode, if it doesn't exist.\n",
      " |\n",
      " |  unlink(self, missing_ok=False)\n",
      " |      Remove this file or link.\n",
      " |      If the path is a directory, use rmdir() instead.\n",
      " |\n",
      " |  walk(self, top_down=True, on_error=None, follow_symlinks=False)\n",
      " |      Walk the directory tree from this directory, similar to os.walk().\n",
      " |\n",
      " |  write_bytes(self, data)\n",
      " |      Open the file in bytes mode, write to it, and close the file.\n",
      " |\n",
      " |  write_text(self, data, encoding=None, errors=None, newline=None)\n",
      " |      Open the file in text mode, write to it, and close the file.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Path:\n",
      " |\n",
      " |  cwd()\n",
      " |      Return a new path pointing to the current working directory.\n",
      " |\n",
      " |  home()\n",
      " |      Return a new path pointing to the user's home directory (as\n",
      " |      returned by os.path.expanduser('~')).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from Path:\n",
      " |\n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Construct a PurePath from one or several strings and or existing\n",
      " |      PurePath objects.  The strings and path objects are combined so as\n",
      " |      to yield a canonicalized path, which is incorporated into the\n",
      " |      new PurePath object.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from PurePath:\n",
      " |\n",
      " |  __bytes__(self)\n",
      " |      Return the bytes representation of the path.  This is only\n",
      " |      recommended to use under Unix.\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __fspath__(self)\n",
      " |\n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |\n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __rtruediv__(self, key)\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Return the string representation of the path, suitable for\n",
      " |      passing to system calls.\n",
      " |\n",
      " |  __truediv__(self, key)\n",
      " |\n",
      " |  as_posix(self)\n",
      " |      Return the string representation of the path with forward (/)\n",
      " |      slashes.\n",
      " |\n",
      " |  as_uri(self)\n",
      " |      Return the path as a 'file' URI.\n",
      " |\n",
      " |  is_absolute(self)\n",
      " |      True if the path is absolute (has both a root and, if applicable,\n",
      " |      a drive).\n",
      " |\n",
      " |  is_relative_to(self, other, /, *_deprecated)\n",
      " |      Return True if the path is relative to another path or False.\n",
      " |\n",
      " |  is_reserved(self)\n",
      " |      Return True if the path contains one of the special names reserved\n",
      " |      by the system, if any.\n",
      " |\n",
      " |  joinpath(self, *pathsegments)\n",
      " |      Combine this path with one or several arguments, and return a\n",
      " |      new path representing either a subpath (if all arguments are relative\n",
      " |      paths) or a totally different path (if one of the arguments is\n",
      " |      anchored).\n",
      " |\n",
      " |  match(self, path_pattern, *, case_sensitive=None)\n",
      " |      Return True if this path matches the given pattern.\n",
      " |\n",
      " |  relative_to(self, other, /, *_deprecated, walk_up=False)\n",
      " |      Return the relative path to another path identified by the passed\n",
      " |      arguments.  If the operation is not possible (because this is not\n",
      " |      related to the other path), raise ValueError.\n",
      " |\n",
      " |      The *walk_up* parameter controls whether `..` may be used to resolve\n",
      " |      the path.\n",
      " |\n",
      " |  with_name(self, name)\n",
      " |      Return a new path with the file name changed.\n",
      " |\n",
      " |  with_segments(self, *pathsegments)\n",
      " |      Construct a new path object from any number of path-like objects.\n",
      " |      Subclasses may override this method to customize how new path objects\n",
      " |      are created from methods like `iterdir()`.\n",
      " |\n",
      " |  with_stem(self, stem)\n",
      " |      Return a new path with the stem changed.\n",
      " |\n",
      " |  with_suffix(self, suffix)\n",
      " |      Return a new path with the file suffix changed.  If the path\n",
      " |      has no suffix, add given suffix.  If the given suffix is an empty\n",
      " |      string, remove the suffix from the path.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from PurePath:\n",
      " |\n",
      " |  anchor\n",
      " |      The concatenation of the drive and root, or ''.\n",
      " |\n",
      " |  drive\n",
      " |      The drive prefix (letter or UNC path), if any.\n",
      " |\n",
      " |  name\n",
      " |      The final path component, if any.\n",
      " |\n",
      " |  parent\n",
      " |      The logical parent of the path.\n",
      " |\n",
      " |  parents\n",
      " |      A sequence of this path's logical parents.\n",
      " |\n",
      " |  parts\n",
      " |      An object providing sequence-like access to the\n",
      " |      components in the filesystem path.\n",
      " |\n",
      " |  root\n",
      " |      The root of the path, if any.\n",
      " |\n",
      " |  stem\n",
      " |      The final path component, minus its last suffix.\n",
      " |\n",
      " |  suffix\n",
      " |      The final component's last suffix, if any.\n",
      " |\n",
      " |      This includes the leading period. For example: '.txt'\n",
      " |\n",
      " |  suffixes\n",
      " |      A list of the final component's suffixes, if any.\n",
      " |\n",
      " |      These include the leading periods. For example: ['.tar', '.gz']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "__pycache__\n",
      "iframe_figures\n",
      "in-class\n",
      "static\n",
      "templates\n"
     ]
    }
   ],
   "source": [
    "# Sakārtosim direktorijas saturu alfabēta secībā\n",
    "\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "  if item.is_dir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "Test-directory\n",
      "__pycache__\n",
      "iframe_figures\n",
      "in-class\n",
      "static\n",
      "templates\n"
     ]
    }
   ],
   "source": [
    "# Izveidosim jaunu direktoriju (zem patreizējās darba direktorijas)\n",
    "\n",
    "new_dir = Path(\"Test-directory\")   # pēc noklusējuma: zem patreizējās darba direktorijas\n",
    "new_dir.mkdir(exist_ok=True)       # nerādīt kļūdu, ja tāda direktorija jau ir\n",
    "\n",
    "# Drukāsim patreizējās darba direktorijas saturu\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "  if item.is_dir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "Test-directory-2\n",
      "__pycache__\n",
      "iframe_figures\n",
      "in-class\n",
      "static\n",
      "templates\n"
     ]
    }
   ],
   "source": [
    "# Pārsauksim direktroju\n",
    "\n",
    "import os\n",
    "\n",
    "os.rename(\"Test-directory\", \"Test-directory-2\")\n",
    "\n",
    "# Drukāsim patreizējās darba direktorijas saturu\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "  if item.is_dir():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzēsīsim direktoriju (tai ir jābūt tukšai)\n",
    "\n",
    "new_dir = Path(\"Test-directory-2\")\n",
    "new_dir.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nevar izdzēst direktoriju: Test-directory\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    new_dir = Path(\"Test-directory\")\n",
    "    new_dir.rmdir()\n",
    "\n",
    "except OSError:\n",
    "    print(\"Nevar izdzēst direktoriju:\", new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrācijas nolūkiem izveidosim dažas datnes un direktorijas.\n",
    "\n",
    "Parasti, lai izveidotu datnes, tās tiek atvērtas (`open`) rakstīšanas režīmā un tajās tiek ierakstīts kaut kāds saturs. Tomēr demonstrācijas nolūkiem mēs šeit izmantosim metodi `touch()`, kas ļauj izveidot tukšu datni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izveidosim 2 direktorijas un vairākas tukšas datnes\n",
    "\n",
    "Path(\"Test-directory\").mkdir()\n",
    "Path(\"Test-directory/sub_dir\").mkdir()\n",
    "\n",
    "Path(\"Test-directory/file1.docx\").touch()\n",
    "Path(\"Test-directory/file2.docx\").touch()\n",
    "Path(\"Test-directory/test1.py\").touch()\n",
    "Path(\"Test-directory/sub_dir/file1.docx\").touch()\n",
    "Path(\"Test-directory/sub_dir/file2.csv\").touch()\n",
    "Path(\"Test-directory/sub_dir/test3.csv\").touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      ".ipynb_checkpoints\n",
      "Test-directory\n",
      "Untitled.ipynb\n",
      "__pycache__\n",
      "cities_titles.json\n",
      "decorator_module.py\n",
      "iframe_figures\n",
      "in-class\n",
      "lena.png\n",
      "my_module.py\n",
      "my_module2.py\n",
      "my_module3.py\n",
      "random_4x5_rounded.csv\n",
      "random_4x5_rounded.npy\n",
      "static\n",
      "templates\n",
      "week_10_numerical_computation_numpy.ipynb\n",
      "week_10_numerical_computation_numpy_LV.ipynb\n",
      "week_11_data_analysis_pandas.ipynb\n",
      "week_11_data_analysis_pandas_LV.ipynb\n",
      "week_13_visualization_libraries.ipynb\n",
      "week_13_visualization_libraries_LV.ipynb\n",
      "week_13_visualization_libraries_Matplotlib.ipynb\n",
      "week_13_visualization_libraries_Matplotlib_LV.ipynb\n",
      "week_13_visualization_libraries_Plotly.ipynb\n",
      "week_13_visualization_libraries_Plotly_LV.ipynb\n",
      "week_14_intermediate_Python.ipynb\n",
      "week_14_intermediate_Python_LV.ipynb\n",
      "week_15_web_Flask_Scrapy.ipynb\n",
      "week_15_web_Flask_Scrapy_LV.ipynb\n",
      "week_1_Python_basics.ipynb\n",
      "week_1_Python_basics_LV.ipynb\n",
      "week_2_key_programming_concepts.ipynb\n",
      "week_2_key_programming_concepts_LV.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets.ipynb\n",
      "week_4_functions_tuples_dictionaries_sets_LV.ipynb\n",
      "week_4_practical_assignments_LV.ipynb\n",
      "week_5_standard_library_modules.ipynb\n",
      "week_5_standard_library_modules_LV.ipynb\n",
      "week_7_dictionary.csv\n",
      "week_7_file_handling.ipynb\n",
      "week_7_file_handling_LV.ipynb\n",
      "week_7_practical_assignments_LV.ipynb\n",
      "week_8_classes_objects.ipynb\n",
      "week_8_classes_objects_LV.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Drukāsim patreizējās darba direktorijas saturu\n",
    "\n",
    "cur_dir = Path(\".\")\n",
    "\n",
    "for item in sorted(cur_dir.iterdir()):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ar help() palīdzību ir iespējams apskatīt papildus informāciju par Path objektiem\n",
    "\n",
    "help(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/captsolo/Documents/Code/LU_Python_course/notebooks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datņu meklēšana pēc nosaukumu šabloniem\n",
    "\n",
    "Apskatīsim kā meklēt datnes pēc to nosaukumu šabloniem (piem., `*.docx` lai atrastu visas Microsoft Word datnes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patreizējā darba dirktorijā nav .docx datnes\n",
    "#  - tādēļ glob() izsaukuma rezultātā netiks atgriezts neviens rezultāts\n",
    "\n",
    "matches = cur_dir.glob(\"*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-directory/file1.docx\n",
      "Test-directory/file2.docx\n"
     ]
    }
   ],
   "source": [
    "# Liksim Pythonam meklēt datnes apakšdirektorijās\n",
    "#  - tiks atrastas vairākas datnes \"Test-directory\" direktorijā\n",
    "#  - bet Python neveiks meklēšanu rekursīvi (tālāk iekļautās apakšdirektorijās)\n",
    "\n",
    "matches = cur_dir.glob(\"*/*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-directory/file1.docx\n",
      "Test-directory/file2.docx\n",
      "Test-directory/sub_dir/file1.docx\n"
     ]
    }
   ],
   "source": [
    "# Ja mēs vēlamies meklēt datnes rekursīvi jebkurā apakšdirektorijā:\n",
    "#  - tam var izmantot īpašu \"**\" direktoriju šablonu\n",
    "\n",
    "matches = cur_dir.glob(\"**/*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rglob() ir līdzīgs glob() izsaukumam, kur datņu šablona priekšā ir pievienots \"**/\"\n",
    "\n",
    "matches = cur_dir.rglob(\"*.docx\")\n",
    "\n",
    "for item in sorted(matches):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: Test-directory\n",
      "    file2.docx\n",
      "    test1.py\n",
      "    file1.docx\n",
      "Directory: Test-directory/sub_dir\n",
      "    file2.csv\n",
      "    test3.csv\n",
      "    file1.docx\n"
     ]
    }
   ],
   "source": [
    "# Mēs varam arī \"staigāt\" pa direktoriju koku ar os.walk() funkcijas palīdzību\n",
    "\n",
    "import os\n",
    "\n",
    "# Iziet cauri direktoriju kokam un drukāt direktoriju un datņu nosaukumus\n",
    "for dirpath, dirnames, files in os.walk('Test-directory'):\n",
    "        print(f'Directory: {dirpath}')\n",
    "        for filename in files:\n",
    "            print(\"   \", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.tēma - Teksta datņu rakstīšana un lasīšana\n",
    "\n",
    "Šajā tēmā tiks apskatīta teksta failu lasīšana, papildināšana un rakstīšana.\n",
    "\n",
    "Ar `with` komandas palīdzību var nodrošināt to, ka datne pēc tās atvēršanas tiek korekti aizvērta:\n",
    "\n",
    "```\n",
    "with open(filename, \"w\") as file_object:\n",
    "    file_object.write(\"some text\")\n",
    "```\n",
    "\n",
    "Šajā piemērā komanda `with` atver `filename` datni rakstīšanas režīmā (`\"w\"`), piešķir atvērtās datnes objektu mainīgajam `file_object` un pēc tam, kad `with` komandas koda bloks ir izpildīts, aizver atvērto datni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datņu lasīšana\n",
    "\n",
    "Lai izveidotu datni, ko lasīt, mēs lietosim Jupyter komandu `%%writefile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datne = open(\"datne.txt\", \"r\")\n",
    "\n",
    "# kaut kādas darbības ar šo datni\n",
    "\n",
    "datne.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_file.txt\n",
    "first,second,third\n",
    "1,2,3\n",
    "4,5,6\n",
    "7,8,9\n",
    "\n",
    "Χαιρετισμούς από τη Ρίγα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datnes atvēršana tiks veikta ar komandas \"with\" palīdzību\n",
    "#  - \"r\" norāda, ka datne ir jāatver lasīšanas režīmā\n",
    "\n",
    "with open(\"test_file.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# nodrukāt nolasīto datnes saturu\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open in module _io:\n",
      "\n",
      "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
      "    Open file and return a stream.  Raise OSError upon failure.\n",
      "\n",
      "    file is either a text or byte string giving the name (and the path\n",
      "    if the file isn't in the current working directory) of the file to\n",
      "    be opened or an integer file descriptor of the file to be\n",
      "    wrapped. (If a file descriptor is given, it is closed when the\n",
      "    returned I/O object is closed, unless closefd is set to False.)\n",
      "\n",
      "    mode is an optional string that specifies the mode in which the file\n",
      "    is opened. It defaults to 'r' which means open for reading in text\n",
      "    mode.  Other common values are 'w' for writing (truncating the file if\n",
      "    it already exists), 'x' for creating and writing to a new file, and\n",
      "    'a' for appending (which on some Unix systems, means that all writes\n",
      "    append to the end of the file regardless of the current seek position).\n",
      "    In text mode, if encoding is not specified the encoding used is platform\n",
      "    dependent: locale.getencoding() is called to get the current locale encoding.\n",
      "    (For reading and writing raw bytes use binary mode and leave encoding\n",
      "    unspecified.) The available modes are:\n",
      "\n",
      "    ========= ===============================================================\n",
      "    Character Meaning\n",
      "    --------- ---------------------------------------------------------------\n",
      "    'r'       open for reading (default)\n",
      "    'w'       open for writing, truncating the file first\n",
      "    'x'       create a new file and open it for writing\n",
      "    'a'       open for writing, appending to the end of the file if it exists\n",
      "    'b'       binary mode\n",
      "    't'       text mode (default)\n",
      "    '+'       open a disk file for updating (reading and writing)\n",
      "    ========= ===============================================================\n",
      "\n",
      "    The default mode is 'rt' (open for reading text). For binary random\n",
      "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
      "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
      "    raises an `FileExistsError` if the file already exists.\n",
      "\n",
      "    Python distinguishes between files opened in binary and text modes,\n",
      "    even when the underlying operating system doesn't. Files opened in\n",
      "    binary mode (appending 'b' to the mode argument) return contents as\n",
      "    bytes objects without any decoding. In text mode (the default, or when\n",
      "    't' is appended to the mode argument), the contents of the file are\n",
      "    returned as strings, the bytes having been first decoded using a\n",
      "    platform-dependent encoding or using the specified encoding if given.\n",
      "\n",
      "    buffering is an optional integer used to set the buffering policy.\n",
      "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
      "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
      "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
      "    given, the default buffering policy works as follows:\n",
      "\n",
      "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
      "      is chosen using a heuristic trying to determine the underlying device's\n",
      "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
      "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
      "\n",
      "    * \"Interactive\" text files (files for which isatty() returns True)\n",
      "      use line buffering.  Other text files use the policy described above\n",
      "      for binary files.\n",
      "\n",
      "    encoding is the name of the encoding used to decode or encode the\n",
      "    file. This should only be used in text mode. The default encoding is\n",
      "    platform dependent, but any encoding supported by Python can be\n",
      "    passed.  See the codecs module for the list of supported encodings.\n",
      "\n",
      "    errors is an optional string that specifies how encoding errors are to\n",
      "    be handled---this argument should not be used in binary mode. Pass\n",
      "    'strict' to raise a ValueError exception if there is an encoding error\n",
      "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
      "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
      "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
      "    for a list of the permitted encoding error strings.\n",
      "\n",
      "    newline controls how universal newlines works (it only applies to text\n",
      "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
      "    follows:\n",
      "\n",
      "    * On input, if newline is None, universal newlines mode is\n",
      "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
      "      these are translated into '\\n' before being returned to the\n",
      "      caller. If it is '', universal newline mode is enabled, but line\n",
      "      endings are returned to the caller untranslated. If it has any of\n",
      "      the other legal values, input lines are only terminated by the given\n",
      "      string, and the line ending is returned to the caller untranslated.\n",
      "\n",
      "    * On output, if newline is None, any '\\n' characters written are\n",
      "      translated to the system default line separator, os.linesep. If\n",
      "      newline is '' or '\\n', no translation takes place. If newline is any\n",
      "      of the other legal values, any '\\n' characters written are translated\n",
      "      to the given string.\n",
      "\n",
      "    If closefd is False, the underlying file descriptor will be kept open\n",
      "    when the file is closed. This does not work when a file name is given\n",
      "    and must be True in that case.\n",
      "\n",
      "    A custom opener can be used by passing a callable as *opener*. The\n",
      "    underlying file descriptor for the file object is then obtained by\n",
      "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
      "    file descriptor (passing os.open as *opener* results in functionality\n",
      "    similar to passing None).\n",
      "\n",
      "    open() returns a file object whose type depends on the mode, and\n",
      "    through which the standard file operations such as reading and writing\n",
      "    are performed. When open() is used to open a file in a text mode ('w',\n",
      "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
      "    a file in a binary mode, the returned class varies: in read binary\n",
      "    mode, it returns a BufferedReader; in write binary and append binary\n",
      "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
      "    a BufferedRandom.\n",
      "\n",
      "    It is also possible to use a string or bytearray as a file for both\n",
      "    reading and writing. For strings StringIO can be used like a file\n",
      "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
      "    opened in a binary mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "Χαιρετισμούς από τη Ρίγα\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ar \"encoding\" parametera palīdzību var norādīt simbolu kodējumu (parasti \"utf-8\")\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "\n",
      "1,2,3\n",
      "\n",
      "4,5,6\n",
      "\n",
      "7,8,9\n",
      "\n",
      "\n",
      "\n",
      "Χαιρετισμούς από τη Ρίγα\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Datni var nolasīt arī līniju pa līnijai (line-by-line)\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "Χαιρετισμούς από τη Ρίγα\n"
     ]
    }
   ],
   "source": [
    "# Nodzēsīsim liekos jaunas rindas simbolus\n",
    "\n",
    "with open(\"test_file.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "Χαιρετισμούς από τη Ρίγα\n"
     ]
    }
   ],
   "source": [
    "# Kā open() funkcijas parametru var norādīt arī Path() objektus\n",
    "\n",
    "test_file = Path(\"test_file.txt\")\n",
    "\n",
    "with open(test_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first,second,third\n",
      "1,2,3\n",
      "4,5,6\n",
      "7,8,9\n",
      "\n",
      "Χαιρετισμούς από τη Ρίγα\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "with open(test_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        \n",
    "        print(line)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datņu rakstīšana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lai datnē ierakstītu jaunu saturu (dzēšot iepriekšējo saturu, ja tāda datne jau ir), \n",
    "# tā ir jāatver \"w\" (write) režīmā.\n",
    "\n",
    "text = \"\"\"\n",
    "This is another file.\n",
    "It contains lines of text.\n",
    "\"\"\"\n",
    "\n",
    "# Pielietosim Path() objektu\n",
    "write_file_path = Path(\"write_file.txt\")\n",
    "\n",
    "with open(write_file_path, \"w\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pārbaudīsim vai teksta rinda ir ierakstīta šajā datnē\n",
    "\n",
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datnes var atvērt arī pievienošanas režīmā \"a\" (append). Tādā gadījumā\n",
    "# jaunais saturs tiks pievienots datnes beigās, nepārrakstot esošo saturu.\n",
    "\n",
    "with open(write_file_path, \"a\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(\"We are appending text at the end of the file.\")\n",
    "    write_file.write(\"One more line here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n"
     ]
    }
   ],
   "source": [
    "# Pārbaudīsim datnes saturu\n",
    "\n",
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No jauna ierakstītās teksta rindiņas saplūda vienā rindiņā.\n",
    "# Lai tas nenotiktu, rindiņu beigās ir jāpievieno jaunas rindiņas\n",
    "# simbols \"\\n\".\n",
    "\n",
    "with open(write_file_path, \"a\", encoding=\"utf-8\") as write_file:\n",
    "\n",
    "    # add the newline character to start on a new line\n",
    "    write_file.write(\"\\n\")\n",
    "    \n",
    "    write_file.write(\"This text should be on a new line.\\n\")\n",
    "    write_file.write(\"One more line here.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n",
      "This text should be on a new line.\n",
      "One more line here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varam rakstīt datnē arī ar komandu print()\n",
    "\n",
    "with open(write_file_path, \"a\", encoding=\"utf-8\") as write_file:\n",
    "    print(\"One more line here.\", file=write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n",
      "This text should be on a new line.\n",
      "One more line here.\n",
      "One more line here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(write_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is another file.\\nIt contains lines of text.\\nWe are appending text at the end of the file.One more line here.\\nThis text should be on a new line.\\nOne more line here.\\nOne more line here.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is another file.\n",
      "It contains lines of text.\n",
      "We are appending text at the end of the file.One more line here.\n",
      "This text should be on a new line.\n",
      "One more line here.\n",
      "One more line here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzēst izveidoto datni\n",
    "\n",
    "os.remove(\"test_file.txt\")\n",
    "\n",
    "write_file_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.tēma - Bināro un cita veida datņu lasīšana un rakstīšana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binārās datnes\n",
    "\n",
    "Lai darbotos ar binārām datnēm, to atvēršanas režīmam ir jāpievieno burts `\"b\"` (piem., `\"rb\"` binārās datnes lasīšanai).\n",
    "\n",
    "Binārajām datnēm nav simbolu kodējums (tās ir tikai baitu virknes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0123456789abcdef'\n"
     ]
    }
   ],
   "source": [
    "# Izveidojam baitu objektu\n",
    "\n",
    "data = b'0123456789abcdef'\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rakstam saturu datnē\n",
    "\n",
    "write_binary_path = Path(\"write_file.bin\")\n",
    "\n",
    "with open(write_binary_path, \"wb\") as write_file:\n",
    "    write_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0123456789abcdef'\n"
     ]
    }
   ],
   "source": [
    "# Nolasām datnes saturu\n",
    "\n",
    "with open(write_binary_path, \"rb\") as read_file:\n",
    "    data_read = read_file.read()\n",
    "    print(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'8'\n",
      "\n",
      "b'd'\n"
     ]
    }
   ],
   "source": [
    "# Ar seek() metodes palīdzību var norādīt uz vietu datnē, kur \n",
    "# veikt tālākās darbības.\n",
    "\n",
    "with open(write_binary_path, \"rb\") as read_file:\n",
    "\n",
    "    # iet uz pozīciju 8 un nolasīt 1 baitu\n",
    "    read_file.seek(8)\n",
    "    print(read_file.read(1))\n",
    "\n",
    "    print()\n",
    "\n",
    "    # iet uz poziciju 3 no datnes beigām un nolasīt 1 baitu\n",
    "    read_file.seek(-3, 2)\n",
    "    print(read_file.read(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function seek:\n",
      "\n",
      "seek(target, whence=0, /) method of _io.BufferedReader instance\n",
      "    Change the stream position to the given byte offset.\n",
      "\n",
      "      offset\n",
      "        The stream position, relative to 'whence'.\n",
      "      whence\n",
      "        The relative position to seek from.\n",
      "\n",
      "    The offset is interpreted relative to the position indicated by whence.\n",
      "    Values for whence are:\n",
      "\n",
      "    * os.SEEK_SET or 0 -- start of stream (the default); offset should be zero or positive\n",
      "    * os.SEEK_CUR or 1 -- current stream position; offset may be negative\n",
      "    * os.SEEK_END or 2 -- end of stream; offset is usually negative\n",
      "\n",
      "    Return the new absolute position.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(read_file.seek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_file.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_file.txt\n",
    "first,second,third\n",
    "1,2,3\n",
    "4,5,6\n",
    "7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'first,second,third\\n1,2,3\\n4,5,6\\n7,8,9\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_file.txt\", \"rb\") as read_file:\n",
    "    data_read = read_file.read()\n",
    "    print(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on bytes object:\n",
      "\n",
      "class bytes(object)\n",
      " |  bytes(iterable_of_ints) -> bytes\n",
      " |  bytes(string, encoding[, errors]) -> bytes\n",
      " |  bytes(bytes_or_buffer) -> immutable copy of bytes_or_buffer\n",
      " |  bytes(int) -> bytes object of size given by the parameter initialized with null bytes\n",
      " |  bytes() -> empty bytes object\n",
      " |\n",
      " |  Construct an immutable array of bytes from:\n",
      " |    - an iterable yielding integers in range(256)\n",
      " |    - a text string encoded using the specified encoding\n",
      " |    - any object implementing the buffer API.\n",
      " |    - an integer\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |\n",
      " |  __buffer__(self, flags, /)\n",
      " |      Return a buffer object that exposes the underlying memory of the object.\n",
      " |\n",
      " |  __bytes__(self, /)\n",
      " |      Convert this value to exact type bytes.\n",
      " |\n",
      " |  __contains__(self, key, /)\n",
      " |      Return bool(key in self).\n",
      " |\n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |\n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |\n",
      " |  __getnewargs__(...)\n",
      " |\n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |\n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |\n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |\n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |\n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |\n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |\n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |\n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |\n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |\n",
      " |  capitalize(...)\n",
      " |      B.capitalize() -> copy of B\n",
      " |\n",
      " |      Return a copy of B with only its first character capitalized (ASCII)\n",
      " |      and the rest lower-cased.\n",
      " |\n",
      " |  center(self, width, fillchar=b' ', /)\n",
      " |      Return a centered string of length width.\n",
      " |\n",
      " |      Padding is done using the specified fill character.\n",
      " |\n",
      " |  count(...)\n",
      " |      B.count(sub[, start[, end]]) -> int\n",
      " |\n",
      " |      Return the number of non-overlapping occurrences of subsection sub in\n",
      " |      bytes B[start:end].  Optional arguments start and end are interpreted\n",
      " |      as in slice notation.\n",
      " |\n",
      " |  decode(self, /, encoding='utf-8', errors='strict')\n",
      " |      Decode the bytes using the codec registered for encoding.\n",
      " |\n",
      " |      encoding\n",
      " |        The encoding with which to decode the bytes.\n",
      " |      errors\n",
      " |        The error handling scheme to use for the handling of decoding errors.\n",
      " |        The default is 'strict' meaning that decoding errors raise a\n",
      " |        UnicodeDecodeError. Other possible values are 'ignore' and 'replace'\n",
      " |        as well as any other name registered with codecs.register_error that\n",
      " |        can handle UnicodeDecodeErrors.\n",
      " |\n",
      " |  endswith(...)\n",
      " |      B.endswith(suffix[, start[, end]]) -> bool\n",
      " |\n",
      " |      Return True if B ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      suffix can also be a tuple of bytes to try.\n",
      " |\n",
      " |  expandtabs(self, /, tabsize=8)\n",
      " |      Return a copy where all tab characters are expanded using spaces.\n",
      " |\n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |\n",
      " |  find(...)\n",
      " |      B.find(sub[, start[, end]]) -> int\n",
      " |\n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |\n",
      " |      Return -1 on failure.\n",
      " |\n",
      " |  hex(...)\n",
      " |      Create a string of hexadecimal numbers from a bytes object.\n",
      " |\n",
      " |        sep\n",
      " |          An optional single character or byte to separate hex bytes.\n",
      " |        bytes_per_sep\n",
      " |          How many bytes between separators.  Positive values count from the\n",
      " |          right, negative values count from the left.\n",
      " |\n",
      " |      Example:\n",
      " |      >>> value = b'\\xb9\\x01\\xef'\n",
      " |      >>> value.hex()\n",
      " |      'b901ef'\n",
      " |      >>> value.hex(':')\n",
      " |      'b9:01:ef'\n",
      " |      >>> value.hex(':', 2)\n",
      " |      'b9:01ef'\n",
      " |      >>> value.hex(':', -2)\n",
      " |      'b901:ef'\n",
      " |\n",
      " |  index(...)\n",
      " |      B.index(sub[, start[, end]]) -> int\n",
      " |\n",
      " |      Return the lowest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |\n",
      " |      Raises ValueError when the subsection is not found.\n",
      " |\n",
      " |  isalnum(...)\n",
      " |      B.isalnum() -> bool\n",
      " |\n",
      " |      Return True if all characters in B are alphanumeric\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |\n",
      " |  isalpha(...)\n",
      " |      B.isalpha() -> bool\n",
      " |\n",
      " |      Return True if all characters in B are alphabetic\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |\n",
      " |  isascii(...)\n",
      " |      B.isascii() -> bool\n",
      " |\n",
      " |      Return True if B is empty or all characters in B are ASCII,\n",
      " |      False otherwise.\n",
      " |\n",
      " |  isdigit(...)\n",
      " |      B.isdigit() -> bool\n",
      " |\n",
      " |      Return True if all characters in B are digits\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |\n",
      " |  islower(...)\n",
      " |      B.islower() -> bool\n",
      " |\n",
      " |      Return True if all cased characters in B are lowercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |\n",
      " |  isspace(...)\n",
      " |      B.isspace() -> bool\n",
      " |\n",
      " |      Return True if all characters in B are whitespace\n",
      " |      and there is at least one character in B, False otherwise.\n",
      " |\n",
      " |  istitle(...)\n",
      " |      B.istitle() -> bool\n",
      " |\n",
      " |      Return True if B is a titlecased string and there is at least one\n",
      " |      character in B, i.e. uppercase characters may only follow uncased\n",
      " |      characters and lowercase characters only cased ones. Return False\n",
      " |      otherwise.\n",
      " |\n",
      " |  isupper(...)\n",
      " |      B.isupper() -> bool\n",
      " |\n",
      " |      Return True if all cased characters in B are uppercase and there is\n",
      " |      at least one cased character in B, False otherwise.\n",
      " |\n",
      " |  join(self, iterable_of_bytes, /)\n",
      " |      Concatenate any number of bytes objects.\n",
      " |\n",
      " |      The bytes whose method is called is inserted in between each pair.\n",
      " |\n",
      " |      The result is returned as a new bytes object.\n",
      " |\n",
      " |      Example: b'.'.join([b'ab', b'pq', b'rs']) -> b'ab.pq.rs'.\n",
      " |\n",
      " |  ljust(self, width, fillchar=b' ', /)\n",
      " |      Return a left-justified string of length width.\n",
      " |\n",
      " |      Padding is done using the specified fill character.\n",
      " |\n",
      " |  lower(...)\n",
      " |      B.lower() -> copy of B\n",
      " |\n",
      " |      Return a copy of B with all ASCII characters converted to lowercase.\n",
      " |\n",
      " |  lstrip(self, bytes=None, /)\n",
      " |      Strip leading bytes contained in the argument.\n",
      " |\n",
      " |      If the argument is omitted or None, strip leading  ASCII whitespace.\n",
      " |\n",
      " |  partition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |\n",
      " |      This will search for the separator sep in the bytes. If the separator is found,\n",
      " |      returns a 3-tuple containing the part before the separator, the separator\n",
      " |      itself, and the part after it.\n",
      " |\n",
      " |      If the separator is not found, returns a 3-tuple containing the original bytes\n",
      " |      object and two empty bytes objects.\n",
      " |\n",
      " |  removeprefix(self, prefix, /)\n",
      " |      Return a bytes object with the given prefix string removed if present.\n",
      " |\n",
      " |      If the bytes starts with the prefix string, return bytes[len(prefix):].\n",
      " |      Otherwise, return a copy of the original bytes.\n",
      " |\n",
      " |  removesuffix(self, suffix, /)\n",
      " |      Return a bytes object with the given suffix string removed if present.\n",
      " |\n",
      " |      If the bytes ends with the suffix string and that suffix is not empty,\n",
      " |      return bytes[:-len(prefix)].  Otherwise, return a copy of the original\n",
      " |      bytes.\n",
      " |\n",
      " |  replace(self, old, new, count=-1, /)\n",
      " |      Return a copy with all occurrences of substring old replaced by new.\n",
      " |\n",
      " |        count\n",
      " |          Maximum number of occurrences to replace.\n",
      " |          -1 (the default value) means replace all occurrences.\n",
      " |\n",
      " |      If the optional argument count is given, only the first count occurrences are\n",
      " |      replaced.\n",
      " |\n",
      " |  rfind(...)\n",
      " |      B.rfind(sub[, start[, end]]) -> int\n",
      " |\n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |\n",
      " |      Return -1 on failure.\n",
      " |\n",
      " |  rindex(...)\n",
      " |      B.rindex(sub[, start[, end]]) -> int\n",
      " |\n",
      " |      Return the highest index in B where subsection sub is found,\n",
      " |      such that sub is contained within B[start,end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |\n",
      " |      Raise ValueError when the subsection is not found.\n",
      " |\n",
      " |  rjust(self, width, fillchar=b' ', /)\n",
      " |      Return a right-justified string of length width.\n",
      " |\n",
      " |      Padding is done using the specified fill character.\n",
      " |\n",
      " |  rpartition(self, sep, /)\n",
      " |      Partition the bytes into three parts using the given separator.\n",
      " |\n",
      " |      This will search for the separator sep in the bytes, starting at the end. If\n",
      " |      the separator is found, returns a 3-tuple containing the part before the\n",
      " |      separator, the separator itself, and the part after it.\n",
      " |\n",
      " |      If the separator is not found, returns a 3-tuple containing two empty bytes\n",
      " |      objects and the original bytes object.\n",
      " |\n",
      " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |\n",
      " |        sep\n",
      " |          The delimiter according which to split the bytes.\n",
      " |          None (the default value) means split on ASCII whitespace characters\n",
      " |          (space, tab, return, newline, formfeed, vertical tab).\n",
      " |        maxsplit\n",
      " |          Maximum number of splits to do.\n",
      " |          -1 (the default value) means no limit.\n",
      " |\n",
      " |      Splitting is done starting at the end of the bytes and working to the front.\n",
      " |\n",
      " |  rstrip(self, bytes=None, /)\n",
      " |      Strip trailing bytes contained in the argument.\n",
      " |\n",
      " |      If the argument is omitted or None, strip trailing ASCII whitespace.\n",
      " |\n",
      " |  split(self, /, sep=None, maxsplit=-1)\n",
      " |      Return a list of the sections in the bytes, using sep as the delimiter.\n",
      " |\n",
      " |      sep\n",
      " |        The delimiter according which to split the bytes.\n",
      " |        None (the default value) means split on ASCII whitespace characters\n",
      " |        (space, tab, return, newline, formfeed, vertical tab).\n",
      " |      maxsplit\n",
      " |        Maximum number of splits to do.\n",
      " |        -1 (the default value) means no limit.\n",
      " |\n",
      " |  splitlines(self, /, keepends=False)\n",
      " |      Return a list of the lines in the bytes, breaking at line boundaries.\n",
      " |\n",
      " |      Line breaks are not included in the resulting list unless keepends is given and\n",
      " |      true.\n",
      " |\n",
      " |  startswith(...)\n",
      " |      B.startswith(prefix[, start[, end]]) -> bool\n",
      " |\n",
      " |      Return True if B starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test B beginning at that position.\n",
      " |      With optional end, stop comparing B at that position.\n",
      " |      prefix can also be a tuple of bytes to try.\n",
      " |\n",
      " |  strip(self, bytes=None, /)\n",
      " |      Strip leading and trailing bytes contained in the argument.\n",
      " |\n",
      " |      If the argument is omitted or None, strip leading and trailing ASCII whitespace.\n",
      " |\n",
      " |  swapcase(...)\n",
      " |      B.swapcase() -> copy of B\n",
      " |\n",
      " |      Return a copy of B with uppercase ASCII characters converted\n",
      " |      to lowercase ASCII and vice versa.\n",
      " |\n",
      " |  title(...)\n",
      " |      B.title() -> copy of B\n",
      " |\n",
      " |      Return a titlecased version of B, i.e. ASCII words start with uppercase\n",
      " |      characters, all remaining cased characters have lowercase.\n",
      " |\n",
      " |  translate(self, table, /, delete=b'')\n",
      " |      Return a copy with each character mapped by the given translation table.\n",
      " |\n",
      " |        table\n",
      " |          Translation table, which must be a bytes object of length 256.\n",
      " |\n",
      " |      All characters occurring in the optional argument delete are removed.\n",
      " |      The remaining characters are mapped through the given translation table.\n",
      " |\n",
      " |  upper(...)\n",
      " |      B.upper() -> copy of B\n",
      " |\n",
      " |      Return a copy of B with all ASCII characters converted to uppercase.\n",
      " |\n",
      " |  zfill(self, width, /)\n",
      " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      " |\n",
      " |      The original string is never truncated.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  fromhex(string, /)\n",
      " |      Create a bytes object from a string of hexadecimal numbers.\n",
      " |\n",
      " |      Spaces between two numbers are accepted.\n",
      " |      Example: bytes.fromhex('B9 01EF') -> b'\\\\xb9\\\\x01\\\\xef'.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  __new__(*args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |\n",
      " |  maketrans(frm, to, /)\n",
      " |      Return a translation table useable for the bytes or bytearray translate method.\n",
      " |\n",
      " |      The returned table will be one where each byte in frm is mapped to the byte at\n",
      " |      the same position in to.\n",
      " |\n",
      " |      The bytes objects frm and to must be of the same length.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON datnes\n",
    "\n",
    "JSON (JavaScript Object Notation) datnes ļauj tajās saglabāt un no tām nolasīt sarežģītākas Python objektu hierarhijas (vārdnīcas, sarakstus, ...).\n",
    "\n",
    "https://www.json.org/json-en.html\n",
    "\n",
    "JSON formāta pamatā ir divi saliktie datu tipi:\n",
    "- kolekcija ar atslēgu/vērtību pāriem (Python: vārdnīca)\n",
    "- sakārtots vērtību saraksts (Python: saraksts)\n",
    "\n",
    "Šajos objektos var būt iekšā vienkāršāki datu veidi, piemēram, skaitļi un teksta virknes.\n",
    "\n",
    "Python vārdnīca, kas satur sarakstu un vēl vienu vārdnīcu:\n",
    "```\n",
    "json_object = {\n",
    "  \"key 1\": \"value 1\",\n",
    "  \"key 2\": [\"value 2\", \"is\", \"a\", \"list\"],\n",
    "  \"key 3\": {\"lists and dictionaries\": \"can be nested\"}\n",
    "}\n",
    "```\n",
    "\n",
    "Darbam ar JSON datiem var izmantot Python [json](https://docs.python.org/3/library/json.html) bibliotēku:\n",
    "\n",
    "- `json.dump()` – saglabāt strukturētus datus JSON datnē\n",
    "- `json.dumps()` – atgriezt strukturētus datus JSON teksta rindas formā\n",
    "- `json.load()` – nolasīt strukturētus datus no JSON datnes\n",
    "- `json.loads()` – nolasīt strukturētus datus no JSON teksta rindas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati, ko vēlamies saglabāt JSON formā\n",
    "#  - saraksts, kas satur Python vārdnīcu, kas satur kortežu\n",
    "\n",
    "data = [\n",
    "    'foo', \n",
    "    {'bar': ('baz', None, 1.0, 2)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo', {'bar': ('baz', None, 1.0, 2)}]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bar': ('baz', None, 1.0, 2)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('baz', None, 1.0, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][\"bar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saglabājam datus JSON datnē\n",
    "\n",
    "file_path = Path(\"test_data.json\")\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file_out:\n",
    "    json.dump(data, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n"
     ]
    }
   ],
   "source": [
    "# Apskatīsim izveidotās datnes saturu\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file_in:\n",
    "    for line in file_in:\n",
    "        print(repr(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nolasīsim strukturētus datus no izveidotās JSON datnes\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file_in:\n",
    "    new_data = json.load(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ['baz', None, 1.0, 2]}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nolasītie dati izskatās *gandrīz* tāpat kā sākotnējā datu struktūra,\n",
    "# vienīgi korteža vietā tagad ir saraksts (jo JSON datņu formātam \n",
    "# nav atsevišķs korteža datu tips).\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baz', None, 1.0, 2]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ar nolasītajiem datiem var darboties tāpat kā ar jebkādu citu \n",
    "# Python datu struktūru\n",
    "\n",
    "new_data[1]['bar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Python datu struktūras var saglabāt un nolasīt arī JSON teksta rindu formā:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ('baz', None, 1.0, 2)}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = json.dumps(data)\n",
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', {'bar': ['baz', None, 1.0, 2]}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = json.loads(json_str)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV datnes\n",
    "\n",
    "CSV (comma separated values / ar komatiem atdalītas vērtības) datnes ļauj mums darboties ar tabulveida datiem, kas sastāv no rindiņām, kur katra rindiņa satur vērtības (tabulas šūnu saturu), kuras parasti tiek atdalītas viena no otras ar komatu.\n",
    "\n",
    "Darbībām ar CSV datnēm ir paredzēta [csv](https://docs.python.org/3/library/csv.html) bibliotēka.\n",
    "\n",
    "Vēl viena bibliotēka, kura ļauj darboties ar CSV datnēm, ir [Pandas](https://pandas.pydata.org/). To mēs apgūsim vēlāk šajā kursā."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [[\"apple\", \"ābols\"], [\"pear\", \"bumbieris\"], [\"dog\", \"suns\"], [\"white\", \"balts\"], [\"black\", \"melns\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sākumā atvērsim CSV datni rakstīšanas režīmā\n",
    "\n",
    "with open(\"data.csv\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    csv_file = csv.writer(out_file, lineterminator=\"\\n\")\n",
    "\n",
    "    for item in data:\n",
    "        csv_file.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple,ābols\n",
      "pear,bumbieris\n",
      "dog,suns\n",
      "white,balts\n",
      "black,melns\n"
     ]
    }
   ],
   "source": [
    "# Linux un macOS operētājsistēmās datnes saturu var apskatīties\n",
    "# ar \"cat\" komandu. Atkomentējiet \"!cat\" komandas rindiņu lai\n",
    "# apskatītu datnes saturu tad, ja Jums ir Linux vai macOS.\n",
    "!cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'ābols']\n",
      "['pear', 'bumbieris']\n",
      "['dog', 'suns']\n",
      "['white', 'balts']\n",
      "['black', 'melns']\n"
     ]
    }
   ],
   "source": [
    "# Nolasīsim datnes saturu\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"data.csv\", \"r\", encoding=\"utf-8\") as in_file:\n",
    "    csv_file = csv.reader(in_file)\n",
    "\n",
    "    for item in csv_file:\n",
    "        print(item)\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'ābols'],\n",
       " ['pear', 'bumbieris'],\n",
       " ['dog', 'suns'],\n",
       " ['white', 'balts'],\n",
       " ['black', 'melns']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citi datņu veidi\n",
    "\n",
    "Python ļauj darboties ar dažāda veida datnēm, t.sk. ar datņu arhīviem:\n",
    "\n",
    "- [gzip](https://docs.python.org/3/library/gzip.html) arhīvu datņu atbalsts\n",
    "- [Python's zipfile: Manipulate Your ZIP Files Efficiently](https://realpython.com/python-zipfile/)\n",
    "\n",
    "Python iekļautais dažādu arhīvu datņu tipu atbalsts ļauj no arhīva datnēm lasīt datus, tos pirms tam neatarhivējot. Tas var būt noderīgi gadījumos, kad ir jādarbojas ar lielām arhivētām datnēm. \n",
    "\n",
    "Python ir [pickle bibliotēka](https://docs.python.org/3/library/pickle.html), kura ļauj datnēs saglabāt arī sarežģītākus Python objektus, kurus nav iespējams saglabāt vienkāršās JSON datnēs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktiskais uzdevums\n",
    "\n",
    "Izveidojiet programmu, kura:\n",
    "\n",
    "1. Atrod visas CSV datnes, kuras ir patreizējā darba direktorijā vai tās apakašdirektorijās, un nodrukā šo datņu sarakstu;\n",
    "2. Atver pirmo atrasto CSV datni un nolasa tās saturu\n",
    "3. Nodrukā šīs datnes pirmos 10 ierakstus:\n",
    "   - katras tabulas šūnas saturu drukāt jaunā rindā\n",
    "   - ierakstus vienu no otra atdalīt ar tukšu rindu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopsavilkums\n",
    "\n",
    "Ko mēs iemācījāmies šajā nodarbībā:\n",
    "* Kā Python valodā darboties ar direktorijām\n",
    "* Kā darboties ar teksta un binārajām datnēm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papildus tēma - Vārdnīcu īsā sintakse\n",
    "\n",
    "Vārdnīcu veidošanas īsā sintakse (*dictionary comprehension*) piedāvā kompaktu veidu vārdnīcu objektu izveidošanai.\n",
    "\n",
    "- `{item[0]: item[1] for item in some_list if some_condition}`\n",
    "\n",
    "Šajā piemērā katrai `item` vērtībai tiks izveidots atbilstošs vārdnīcas ieraksts, kurā `item[0]` kļūs par atslēgu un `item[1]` - par atslēgai atbilstošo vērtību."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\"apple\", \"ābols\"], [\"pear\", \"bumbieris\"], [\"dog\", \"suns\"], [\"white\", \"balts\"], [\"black\", \"melns\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar \"for\" ciklu (bez vārdnīcu īsās sintakses)\n",
    "\n",
    "new_dict = {}\n",
    "\n",
    "for key, value in data:\n",
    "    new_dict[key] = value\n",
    "\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 koda rindiņā ar vārdnīcu īso sintaksti\n",
    "\n",
    "new_dict2 = {key: value for key, value in data}\n",
    "\n",
    "new_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict2[\"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papildus resursi\n",
    "\n",
    "### Tēma 1 - darbības ar direktorijām\n",
    "\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) - Objektorientēti failsistēmas ceļi\n",
    "- [Working with files in Python](https://realpython.com/working-with-files-in-python/)\n",
    "\n",
    "### Tēma 2 - datņu lasīšana un rakstīšana\n",
    "\n",
    "- [Reading and writing files](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) - Python apmācības materiāls\n",
    "- [Reading and writing files](https://automatetheboringstuff.com/2e/chapter9/) - grāmata \"Automate the boring stuff with Python\"\n",
    "- [Working with files in Python](https://realpython.com/working-with-files-in-python/)\n",
    "\n",
    "### Tēma 3 - darbs ar binārajām un cita veida datnēm\n",
    "\n",
    "- [Reading binary files in Python](https://www.pythonmorsels.com/reading-binary-files-in-python/#top)\n",
    "- [gzip — Support for gzip files](https://docs.python.org/3/library/gzip.html)\n",
    "- [Working With JSON Data in Python](https://realpython.com/python-json/)\n",
    "- [Python's zipfile: Manipulate Your ZIP Files Efficiently](https://realpython.com/python-zipfile/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
